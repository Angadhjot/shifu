# zookeeperServers is used for distributed training 
zookeeperServers=

# hadoopNumParallel is for parallelity for when using mapreduce mode
# deprecated: there is auto parallel setting in all pig scripts to help user no need to set this number
#hadoopNumParallel=40

# hadoopJobQueue specifies the hadoop job queue
hadoopJobQueue=default

# localNumParallel is for parallelity for when using local mode
localNumParallel=6

# how many records per message
recordCntPerMessage=100000

# fix a bug on hdp 2.4.1 by default mapreduce.job.max.split.locations is 10
mapreduce.job.max.split.locations=100

# disable map output compress because some issue for snappy config in our clusters
mapreduce.map.output.compress=false

# set to 15mins (default 10mins)
mapreduce.task.timeout=900000

## tunning for rf, in rf, tree models are stored in master memory, if two many models, please tune such parameters 
# mapreduce.map.memory.mb=3072
# mapreduce.map.java.opts=-Xms2G -Xmx2G -server -XX:MaxPermSize=512M -XX:PermSize=512M -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=8 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
